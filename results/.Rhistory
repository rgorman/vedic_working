y <- 0
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
log(y_hat^y * ((1-y_hat)^(1-y)))
## cross-entropy loss
y <- 1
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
log(y_hat^y * ((1-y_hat)^(1-y)))
-log(y_hat^y * ((1-y_hat)^(1-y)))
y_hat <- .7
y_hat^y * ((1-y_hat)^(1-y))
-log(y_hat^y * ((1-y_hat)^(1-y)))
(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
## cross-entropy loss
y <- 0
y_hat^y * ((1-y_hat)^(1-y))
-log(y_hat^y * ((1-y_hat)^(1-y)))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
(-(y*log(y_hat)) + ((1-y)*log(1-y_hat)))
((y*log(y_hat)) + ((1-y)*log(1-y_hat)))
-1*(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-log(y_hat^y * ((1-y_hat)^(1-y)))
(y*log(y_hat)) + ((1-y)*log(1-y_hat)) * -1
###
xx <- c(3, 2)
###
x <- c(3, 2)
exp(-x) / (1 + (exp(-x)))
w <- c(0, 0, 0)
x*w
###
x <- c(3, 2, 1)
w <- c(0, 0, 0)
x*w
exp(x*w) / (1 + (exp(x*w)))
ss <- exp(x*w) / (1 + (exp(x*w)))
ss - 1
(ss - 1) * x
g1 <- (ss - 1) * x
-.1 * g1
GNT.df <- readRDS("~/Github/GNT-stylometry/proiel/data/GNT_binary_valued.RDS")
colnames(GNT.df)[1:100]
require(tidyverse)
GNT.df$book_id %>% unique()
Hebr.df <- GNT.df %>%
filter(book_id = "HEB")
Hebr.df <- GNT.df %>%
filter(book_id == "HEB")
Rom.df <- GNT.df %>%
filter(book_id == "ROM")
GNT.df$self_proiel_pos %>% unique()
Hebr.df %>%
filter(self_proiel_pos == "common_noun")
View(Hebr.df)
Hebr.df %>%
filter(self_proiel_pos == "common_noun") %>%
select(id, form)
GNT.df$self_gender %>% unique()
GNT.df$self_gender
GNT.df$self_gender %>% unique()
Hebr.df %>%
filter(self_gender == "masculine_or_neuter")
Hebr.df %>%
filter(self_gender == "masculine_or_neuter") %>%
select(id, form)
View(Hebr.df)
Hebr.df %>%
filter(self_gender == "masculine_or_neuter") %>%
select(id, form, citation_part)
Hebr.df %>%
filter(self_case == "dative") %>%
select(id, form, citation_part)
Rom.df %>%
filter(self_case == "dative") %>%
select(id, form, citation_part)
Rom.df %>%
filter(self_case == "dative")
Rom.df %>%
filter(self_case == "dative") %>%
summarise(ct = n())
Rom.df %>%
filter(self_case == "dative") %>%
group_by(self_gender)
Rom.df %>%
filter(self_case == "dative") %>%
group_by(self_gender) %>%
summarise(ct = n())
x <- 20:40
20/x
30/33
names(x) <- x
20/x
25/40
25*(1/.625)
seq(1142, )
seq(1142, length.out = 141 )
seq(1283, length.out = 141 )
seq(1424, length.out = 141 )
seq(2001, length.out = 83 )
seq(2084, length.out = 83 )
seq(5223, length.out = 111 )
seq(5139, length.out = 138 )
seq(5277, length.out = 138 )
5277+138
140*20
seq(1103, length.out = 102 )
seq(1103, length.out = 100 )
seq(2085, length.out = 80 )
seq(2165, length.out = 80 )
seq(2245, length.out = 80 )
seq(3088, length.out = 90 )
seq(3178, length.out = 89 )
seq(5001, length.out = 135 )
seq(5136, length.out = 140 )
seq(5276, length.out = 140 )
seq(5416, length.out = 140 )
seq(5416, length.out = 135 )
seq(6001, length.out = 135 )
seq(6136, length.out = 140 )
seq(6276, length.out = 140 )
seq(6416, length.out = 140 )
seq(8084, length.out = 80 )
seq(1001, length.out = 101 )
seq(1102, length.out = 101 )
seq(1102, length.out = 110 )
seq(1212, length.out = 110 )
seq(1322, length.out = 110 )
seq(1322, length.out = 107 )
seq(2001, length.out = 82 )
seq(2082, length.out = 88 )
seq(2170, length.out = 88 )
seq(2258, length.out = 87 )
seq(2258, length.out = 22 )
seq(2001, length.out = 82 )
seq(3001, length.out = 90 )
seq(3091, length.out = 88 )
seq(3179, length.out = 88 )
seq(5144, length.out = 132 )
seq(5276, length.out = 132 )
seq(5408, length.out = 143 )
require(tidyverse)
x <- 1:5
combn(x, 2)
combn(x, 23)
combn(x, 5)
combn(x, 1)
combn(1:5, 1)
choose(5, 23)
require(tidyverse)
require(udpipe)
setwd("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda")
files.v <- dir(pattern = "_parsed")
morphs.v <- readRDS("~/Github/vedic/vedic_sandbox/vars/morphs.RDS")
BookAndHymn.v <- files.v %>% str_extract("ṚV.*") %>%
gsub("-.*", "", .) %>%
gsub(", ", "_", .) %>%
gsub("Ṛ", "R", .)
Book.v <- BookAndHymn.v %>%
gsub("RV_", "", .) %>%
gsub("_.*", "", .)
i <- 1
######### add metadata, convert to df, record colnames for morphs
holder.l <- vector(mode = "list", length(files.v))
working.df <- udpipe_read_conllu(files.v[i])
working.df <- add_column(working.df, Book_and_Hymn = BookAndHymn.v[i], .before = TRUE)
working.df <- add_column(working.df, Book_Id = Book.v[i], .before = TRUE)
View(working.df)
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
m <- ncol(z) # for loop: number of cols in z
FileName.v <- paste0( BookAndHymn.v[i], ".RDS")
FileName.v
FileName.v
n <- 1
OldBook.v <- paste0("_", n, "_")
NewBook.v <- paste0("_", "0", n, "_")
OldHymn.v <- paste0("_", n, ".RDS")
NewHymn.v <- paste0("_", "0", n, ".RDS")
FileName.v
gsub( OldBook.v, NewBook.v, FileName.v )
FileName2.v <- gsub( OldBook.v, NewBook.v, FileName.v )
FileName3.v <- gsub(OldHymn.v, NewHymn.v, FileName2.v)
for (n in 1:9) {
OldBook.v <- paste0("_", n, "_")
NewBook.v <- paste0("_", "0", n, "_")
OldHymn.v <- paste0("_", n, ".RDS")
NewHymn.v <- paste0("_", "0", n, ".RDS")
FileName2.v <- gsub( OldBook.v, NewBook.v, FileName.v )
FileName3.v <- gsub(OldHymn.v, NewHymn.v, FileName2.v)
}
OldBook.v <- paste0("_", n, "_")
NewBook.v <- paste0("_", "0", n, "_")
FileName.v
OldBook.v <- paste0("_", n, "_")
FileName2.v <- gsub( OldBook.v, NewBook.v, FileName.v )
n <- 1
OldBook.v <- paste0("_", n, "_")
NewBook.v <- paste0("_", "0", n, "_")
OldHymn.v <- paste0("_", n, ".RDS")
NewHymn.v <- paste0("_", "0", n, ".RDS")
FileName2.v <- gsub( OldBook.v, NewBook.v, FileName.v )
FileName3.v <- gsub(OldHymn.v, NewHymn.v, FileName2.v)
files.v2 <- files.v
files.v2[which(str_detect(files.v2, OldBook.v))]
OldBook.v
files.v2
FileName.v
FileName.v
FileName.v
i <- 2
working.df <- udpipe_read_conllu(files.v[i])
working.df <- add_column(working.df, Book_and_Hymn = BookAndHymn.v[i], .before = TRUE)
working.df <- add_column(working.df, Book_Id = Book.v[i], .before = TRUE)
FileName.v <- paste0( BookAndHymn.v[i], ".RDS")
FileAndPath.v <-  file.path(".", "output", FileName.v)
saveRDS(working.df, FileAndPath.v)
print(paste("completed file", i))
for (i in seq_along(files.v)) {
working.df <- udpipe_read_conllu(files.v[i])
working.df <- add_column(working.df, Book_and_Hymn = BookAndHymn.v[i], .before = TRUE)
working.df <- add_column(working.df, Book_Id = Book.v[i], .before = TRUE)
FileName.v <- paste0( BookAndHymn.v[i], ".RDS")
FileAndPath.v <-  file.path(".", "output", FileName.v)
holder.l[[i]] <- morphs.v
saveRDS(working.df, FileAndPath.v)
print(paste("completed file", i))
}
self_names.v <- paste0("self_", morphs.v)
setwd("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output")
files.v <- dir(pattern = ".RDS")
i <- 1
working.df <- readRDS(files.v[i]) # load file from dir; file should be data frame
x <- working.df$sentence_id %>%
unique() # vector with id number of each sentence
dd_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
}
View(a)
dd_holder.v
working.df <- working.df %>%
mutate(self_POS = upos) # create new col for part of speech of target word (marked with prefix "self")
working.df <- working.df %>%
mutate(self_rel = dep_rel) # ditto for the dependency relation
working.df <- working.df %>%
mutate(self_dd = dd_holder.v) # ditto for dependency distance
working.df[which(working.df$self_dd > 0), "self_arc_dir"] <- "parent_precedes" # ditto for arc direction
working.df[which(working.df$self_dd < 0), "self_arc_dir"] <- "parent_follows"
working.df[, self_names.v] <- NA # add "self-" cols for morphology
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
z[which(z == "")] <- "Not_App"
z[is.na(z)] <- "Not_App"
for (j in seq_len(ncol(z))) {
a <- apply(z[, j, drop=F], 1,   function(x) sub(".*=", "", x)    )
b <- apply(z[, j, drop=F], 1,   function(x) sub("=.*", "", x)    )
b <- paste0("self_", b)
for (n in seq_along(a)) {
working.df[n, b[n]] <- a[n]
}
}
fp <- file.path("parsed_expanded", files.v[i]) # create file path for saving
i <- 10
working.df <- readRDS(files.v[i]) # load file from dir; file should be data frame
x <- working.df$sentence_id %>%
unique() # vector with id number of each sentence
dd_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
}
dd_holder.v
n <- 1
dd_holder.v <- NULL # vector to store result of loop
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
(a$token_id %>%
as.numeric() ) - b )
c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
dd_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
}
dd_holder.v
working.df <- working.df %>%
mutate(self_POS = upos) # create new col for part of speech of target word (marked with prefix "self")
working.df <- working.df %>%
mutate(self_rel = dep_rel) # ditto for the dependency relation
working.df <- working.df %>%
mutate(self_dd = dd_holder.v) # ditto for dependency distance
working.df[which(working.df$self_dd > 0), "self_arc_dir"] <- "parent_precedes" # ditto for arc direction
working.df[which(working.df$self_dd < 0), "self_arc_dir"] <- "parent_follows"
working.df[, self_names.v] <- NA # add "self-" cols for morphology
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
z[which(z == "")] <- "Not_App"
z[is.na(z)] <- "Not_App"
for (j in seq_len(ncol(z))) {
a <- apply(z[, j, drop=F], 1,   function(x) sub(".*=", "", x)    )
b <- apply(z[, j, drop=F], 1,   function(x) sub("=.*", "", x)    )
b <- paste0("self_", b)
for (n in seq_along(a)) {
working.df[n, b[n]] <- a[n]
}
}
fp <- file.path("parsed_expanded", files.v[i]) # create file path for saving
saveRDS(working.df, files.v[i])
print(paste0("completed file ", files.v[i]))
fp <- file.path("." "parsed_expanded", files.v[i]) # create file path for saving
fp <- file.path(".", "parsed_expanded", files.v[i]) # create file path for saving
saveRDS(working.df, fp)
RV_1_107 <- readRDS("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/RV_1_107.RDS")
View(RV_1_107)
RV_1_106 <- readRDS("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/RV_1_106.RDS")
files.v <- dir(pattern = "_parsed")
BookAndHymn.v <- files.v %>% str_extract("ṚV.*") %>%
gsub("-.*", "", .) %>%
gsub(", ", "_", .) %>%
gsub("Ṛ", "R", .)
files.v <- dir(pattern = "_parsed")
files.v <- dir(pattern = "_parsed")
setwd("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda")
files.v <- dir(pattern = "_parsed")
BookAndHymn.v <- files.v %>% str_extract("ṚV.*") %>%
gsub("-.*", "", .) %>%
gsub(", ", "_", .) %>%
gsub("Ṛ", "R", .)
Book.v <- BookAndHymn.v %>%
gsub("RV_", "", .) %>%
gsub("_.*", "", .)
BookAndHymn.v
for (i in seq_along(files.v)) {
working.df <- udpipe_read_conllu(files.v[i])
working.df <- add_column(working.df, Book_and_Hymn = BookAndHymn.v[i], .before = TRUE)
working.df <- add_column(working.df, Book_Id = Book.v[i], .before = TRUE)
FileName.v <- paste0( BookAndHymn.v[i], ".RDS")
FileAndPath.v <-  file.path(".", "output", FileName.v)
holder.l[[i]] <- morphs.v
saveRDS(working.df, FileAndPath.v)
print(paste("completed file", i))
}
setwd("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output")
i <- 10
working.df <- readRDS(files.v[i]) # load file from dir; file should be data frame
files.v <- dir(pattern = ".RDS")
working.df <- readRDS(files.v[i]) # load file from dir; file should be data frame
x <- working.df$sentence_id %>%
unique() # vector with id number of each sentence
dd_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
}
working.df <- working.df %>%
mutate(self_POS = upos) # create new col for part of speech of target word (marked with prefix "self")
working.df <- working.df %>%
mutate(self_rel = dep_rel) # ditto for the dependency relation
working.df <- working.df %>%
mutate(self_dd = dd_holder.v) # ditto for dependency distance
working.df[which(working.df$self_dd > 0), "self_arc_dir"] <- "parent_precedes" # ditto for arc direction
working.df[which(working.df$self_dd < 0), "self_arc_dir"] <- "parent_follows"
working.df[, self_names.v] <- NA # add "self-" cols for morphology
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
z[which(z == "")] <- "Not_App"
z[is.na(z)] <- "Not_App"
for (j in seq_len(ncol(z))) {
a <- apply(z[, j, drop=F], 1,   function(x) sub(".*=", "", x)    )
b <- apply(z[, j, drop=F], 1,   function(x) sub("=.*", "", x)    )
b <- paste0("self_", b)
for (n in seq_along(a)) {
working.df[n, b[n]] <- a[n]
}
}
fp <- file.path(".", "parsed_expanded", files.v[i]) # create file path for saving
saveRDS(working.df, fp)
print(paste0("completed file ", i))
for (i in seq_along(files.v)) { # loop to make separate col for each category of morpho-syntactic data
working.df <- readRDS(files.v[i]) # load file from dir; file should be data frame
# create col with term_id of the parent of each target token
# ditto for dependency distance of each target token
x <- working.df$sentence_id %>%
unique() # vector with id number of each sentence
dd_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
}
working.df <- working.df %>%
mutate(self_POS = upos) # create new col for part of speech of target word (marked with prefix "self")
working.df <- working.df %>%
mutate(self_rel = dep_rel) # ditto for the dependency relation
working.df <- working.df %>%
mutate(self_dd = dd_holder.v) # ditto for dependency distance
working.df[which(working.df$self_dd > 0), "self_arc_dir"] <- "parent_precedes" # ditto for arc direction
working.df[which(working.df$self_dd < 0), "self_arc_dir"] <- "parent_follows"
working.df[, self_names.v] <- NA # add "self-" cols for morphology
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
z[which(z == "")] <- "Not_App"
z[is.na(z)] <- "Not_App"
for (j in seq_len(ncol(z))) {
a <- apply(z[, j, drop=F], 1,   function(x) sub(".*=", "", x)    )
b <- apply(z[, j, drop=F], 1,   function(x) sub("=.*", "", x)    )
b <- paste0("self_", b)
for (n in seq_along(a)) {
working.df[n, b[n]] <- a[n]
}
}
fp <- file.path(".", "parsed_expanded", files.v[i]) # create file path for saving
saveRDS(working.df, fp)
print(paste0("completed file ", i))
}
warnings()
RV_1_17 <- readRDS("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/RV_1_17.RDS")
View(RV_1_17)
RV_9_44 <- readRDS("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/RV_9_44.RDS")
View(RV_9_44)
files.v2 <- files.v
for (n in 1:9) {
OldBook.v <- paste0("_", n, "_")
NewBook.v <- paste0("_", "0", n, "_")
OldHymn.v <- paste0("_", n, ".RDS")
NewHymn.v <- paste0("_", "0", n, ".RDS")
files.v2[which(str_detect(files.v2, OldBook.v))] <- files.v2[which(str_detect(files.v2, OldBook.v))] %>%
gsub(OldBook.v, NewBook.v, .)
files.v2[which(str_detect(files.v2, OldHymn.v))] <- files.v2[which(str_detect(files.v2, OldHymn.v))] %>%
gsub(OldHymn.v, NewHymn.v, .)
}
files.v2
setwd("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/parsed_expanded")
files.v <- dir(pattern = ".RDS")
files.v2 <- files.v
for (n in 1:9) {
OldBook.v <- paste0("_", n, "_")
NewBook.v <- paste0("_", "0", n, "_")
OldHymn.v <- paste0("_", n, ".RDS")
NewHymn.v <- paste0("_", "0", n, ".RDS")
files.v2[which(str_detect(files.v2, OldBook.v))] <- files.v2[which(str_detect(files.v2, OldBook.v))] %>%
gsub(OldBook.v, NewBook.v, .)
files.v2[which(str_detect(files.v2, OldHymn.v))] <- files.v2[which(str_detect(files.v2, OldHymn.v))] %>%
gsub(OldHymn.v, NewHymn.v, .)
}
for (i in seq_along(files.v)) {
x <- readRDS(files.v[i])
fp <- file.path(".", "renumbered", files.v2[i])
saveRDS(x, file = fp)
print(paste0("finished ", i))
}
RV_08_28 <- readRDS("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/parsed_expanded/renumbered/RV_08_28.RDS")
View(RV_08_28)
setwd("~/Github/vedic/Hellwig/sanskrit/dcs/data/conllu/files/Ṛgveda/output/parsed_expanded/renumbered")
files.v <- dir(pattern = ".RDS")
holder.l <- vector(mode = "list", length(files.v))
for (i in seq_along(files.v)) {
x <- readRDS(files.v[i])
holder.l[[i]] <- x
print(paste0("finished ", i))
}
working.df <- do.call(bind_rows, holder.l)
nrow(working.df)
working.df$sentence_id %>%
unique() %>%
length()
## add global token id
a <- 1:nrow(working.df)
working.df <- add_column(working.df, GlobalTokenId = a, .before = TRUE)
View(working.df)
sent.v <- working.df$sentence_id %>%
unique()
parent_holder.v <- NULL
for (n in seq_along(sent.v)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == sent.v[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
parent_holder.v <- c(parent_holder.v,  a$GlobalTokenId[b] %>%
as.numeric() ) # add parent term_token_id values for current sentence to vector
}
working.df$head_token_id
setwd("~/Github/vedic/vedic_sandbox/results")
saveRDS(working.df, combined.df.RDS)
saveRDS(working.df, "combined.df.RDS")
