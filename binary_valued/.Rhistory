b c("POS", "G", "N", "C", "Dep")
b <-  c("POS", "G", "N", "C", "Dep")
combn(a)
combn(a, 1)
m <- 1:5
combn(a, )
combn(a, m)
combn(a, 1)
combn(a, 2)
combn(a, 3)
combn(a, 4)
combn(a, 5)
2^5
b <-  c("P_POS", "P_G", "P_N", "P_C", "P_Dep")
a <- c("S_POS", "S_G", "S_N", "S_C", "S_Dep")
combn(a, 5)
combn(c(a, b), 5)
combn(c(a, b), 1)
combn(c(a, b), 2)
combn(c(a, b), 3)
2^10
log(66)
x <- .833
exp(-x) / (1 + (exp(-x)))
exp(x) / (1 + (exp(x)))
## cross-entropy loss
y <- 1
y_hat <- 1
y_hat^y * ((1-y_hat)^(1-y))
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
y_hat^y
((1-y_hat)^(1-y))
(1-y_hat)
(1-y)
((1-y_hat)^(1-y))
y_hat^y * ((1-y_hat)^(1-y))
## cross-entropy loss
y <- 0
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
log(y_hat^y * ((1-y_hat)^(1-y)))
## cross-entropy loss
y <- 1
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
log(y_hat^y * ((1-y_hat)^(1-y)))
-log(y_hat^y * ((1-y_hat)^(1-y)))
y_hat <- .7
y_hat^y * ((1-y_hat)^(1-y))
-log(y_hat^y * ((1-y_hat)^(1-y)))
(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
## cross-entropy loss
y <- 0
y_hat^y * ((1-y_hat)^(1-y))
-log(y_hat^y * ((1-y_hat)^(1-y)))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
(-(y*log(y_hat)) + ((1-y)*log(1-y_hat)))
((y*log(y_hat)) + ((1-y)*log(1-y_hat)))
-1*(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-log(y_hat^y * ((1-y_hat)^(1-y)))
(y*log(y_hat)) + ((1-y)*log(1-y_hat)) * -1
###
xx <- c(3, 2)
###
x <- c(3, 2)
exp(-x) / (1 + (exp(-x)))
w <- c(0, 0, 0)
x*w
###
x <- c(3, 2, 1)
w <- c(0, 0, 0)
x*w
exp(x*w) / (1 + (exp(x*w)))
ss <- exp(x*w) / (1 + (exp(x*w)))
ss - 1
(ss - 1) * x
g1 <- (ss - 1) * x
-.1 * g1
GNT.df <- readRDS("~/Github/GNT-stylometry/proiel/data/GNT_binary_valued.RDS")
colnames(GNT.df)[1:100]
require(tidyverse)
GNT.df$book_id %>% unique()
Hebr.df <- GNT.df %>%
filter(book_id = "HEB")
Hebr.df <- GNT.df %>%
filter(book_id == "HEB")
Rom.df <- GNT.df %>%
filter(book_id == "ROM")
GNT.df$self_proiel_pos %>% unique()
Hebr.df %>%
filter(self_proiel_pos == "common_noun")
View(Hebr.df)
Hebr.df %>%
filter(self_proiel_pos == "common_noun") %>%
select(id, form)
GNT.df$self_gender %>% unique()
GNT.df$self_gender
GNT.df$self_gender %>% unique()
Hebr.df %>%
filter(self_gender == "masculine_or_neuter")
Hebr.df %>%
filter(self_gender == "masculine_or_neuter") %>%
select(id, form)
View(Hebr.df)
Hebr.df %>%
filter(self_gender == "masculine_or_neuter") %>%
select(id, form, citation_part)
Hebr.df %>%
filter(self_case == "dative") %>%
select(id, form, citation_part)
Rom.df %>%
filter(self_case == "dative") %>%
select(id, form, citation_part)
Rom.df %>%
filter(self_case == "dative")
Rom.df %>%
filter(self_case == "dative") %>%
summarise(ct = n())
Rom.df %>%
filter(self_case == "dative") %>%
group_by(self_gender)
Rom.df %>%
filter(self_case == "dative") %>%
group_by(self_gender) %>%
summarise(ct = n())
x <- 20:40
20/x
30/33
names(x) <- x
20/x
25/40
25*(1/.625)
seq(1142, )
seq(1142, length.out = 141 )
seq(1283, length.out = 141 )
seq(1424, length.out = 141 )
seq(2001, length.out = 83 )
seq(2084, length.out = 83 )
seq(5223, length.out = 111 )
seq(5139, length.out = 138 )
seq(5277, length.out = 138 )
5277+138
140*20
seq(1103, length.out = 102 )
seq(1103, length.out = 100 )
seq(2085, length.out = 80 )
seq(2165, length.out = 80 )
seq(2245, length.out = 80 )
seq(3088, length.out = 90 )
seq(3178, length.out = 89 )
seq(5001, length.out = 135 )
seq(5136, length.out = 140 )
seq(5276, length.out = 140 )
seq(5416, length.out = 140 )
seq(5416, length.out = 135 )
seq(6001, length.out = 135 )
seq(6136, length.out = 140 )
seq(6276, length.out = 140 )
seq(6416, length.out = 140 )
seq(8084, length.out = 80 )
seq(1001, length.out = 101 )
seq(1102, length.out = 101 )
seq(1102, length.out = 110 )
seq(1212, length.out = 110 )
seq(1322, length.out = 110 )
seq(1322, length.out = 107 )
seq(2001, length.out = 82 )
seq(2082, length.out = 88 )
seq(2170, length.out = 88 )
seq(2258, length.out = 87 )
seq(2258, length.out = 22 )
seq(2001, length.out = 82 )
seq(3001, length.out = 90 )
seq(3091, length.out = 88 )
seq(3179, length.out = 88 )
seq(5144, length.out = 132 )
seq(5276, length.out = 132 )
seq(5408, length.out = 143 )
require(tidyverse)
x <- 1:5
combn(x, 2)
combn(x, 23)
combn(x, 5)
combn(x, 1)
combn(1:5, 1)
choose(5, 23)
online.df <- readRDS("~/Github/vedic/vedic_sandbox/online_parse_eval.RDS")
View(online.df)
gold.df <- readRDS("~/Github/vedic/vedic_sandbox/gold_parse_eval.RDS")
x <-  gold.df$sentence_id %>%
str_extract( "[^_]*")
require(tidyverse)
x <-  gold.df$sentence_id %>%
str_extract( "[^_]*")
x %>% unique()
online.df <- add_column(online.df, work_ref = x, .before = TRUE)
books.v <- x %>% unique()
tokenCount.l <- vector(mode = "list", length(books.v))
for (i in seq_along(tokenCount.l)) {
a <- online.df %>%
filter(work_ref == books.v[i]) %>%
nrow()
tokenCount.l[[i]] <- a
}
unlist(tokenCount.l) %>% sum()
tokenCount.l
###############
x <- online.df %>% # make vector of col names
colnames()
x
View(online.df)
x[c(11, 15)]
x[c(11, 15, 18, 19, 20:36)]
x[c(11, 15, 18, 19, 21:36)]
x <- x[c(11, 15, 18, 19, 21:36)]
selected.cols.v <- x
# a loop to make all possible combinations of names in vector of selected cols
selected_vars.list <- vector(mode = "list", 3) # make list to store results
nomina.v <- NULL # vector to store names of list elements
for (k in 1:3) {
selected_vars.list[[k]] <- combn(selected.cols.v, k, simplify = FALSE) # make all possible combinations of variables
nomina.v <- paste(length(selected.cols.v), "Choose",  k, collapse = " ") %>% # create names for elements in list
append(nomina.v, .)
}
freq.tib_simplex <- gather(online.df[,   ], variable_name, variable_value,  na.rm = TRUE) %>%
mutate(combined = paste(paste(variable_name, variable_value, sep = "_Is_"))) %>%
select( combined) %>%
group_by( combined) %>%
summarize(freq = n())  %>%
arrange(desc(freq))
View(freq.tib_simplex)
freq.tib_simplex <- gather(online.df[, selected.cols.v  ], variable_name, variable_value,  na.rm = TRUE) %>%
mutate(combined = paste(paste(variable_name, variable_value, sep = "_Is_"))) %>%
select( combined) %>%
group_by( combined) %>%
summarize(freq = n())  %>%
arrange(desc(freq))
View(freq.tib_simplex)
# extract into separate vectors the variable names for combinations of two morphosyntactic categories
var_1 <- sapply(selected_vars.list[[2]], `[`, 1)
var_2 <- sapply(selected_vars.list[[2]], `[`, 2)
var_1
nomen.v <- paste(var_1, var_2, sep = "_And_") # combine simplex variable names into a combined name: e.g, "self_POS_And_self_rel"
# make matrix to store duplex name-value pairs
r <- nrow(online.df)
c <- length(nomen.v)
duplex_sample.df <- matrix(ncol = c, nrow = r)
colnames(duplex_sample.df) <- nomen.v
View(duplex_sample.df)
# a loop to populate cols with values; values taken from original sample.df
for (i in seq_along(var_1)) {
duplex_sample.df[, nomen.v[i]] <- paste(unlist(online.df[, var_1[i]]), unlist(online.df[, var_2[i] ]), sep = "_And_")
}
duplex_sample.df <- as.data.frame(duplex_sample.df) # convert matrix to data frame (required for next step)
View(duplex_sample.df)
freq.tib_two_plex <- gather(duplex_sample.df[,  ], variable_name, variable_value,  na.rm = TRUE) %>%
mutate(combined = paste(paste(variable_name, variable_value, sep = "_Are_"))) %>%
select( combined) %>%
group_by( combined) %>%
summarize(freq = n())  %>%
arrange(desc(freq))
View(freq.tib_two_plex)
# extract into separate vectors the variable names for combinations of three morpho-syntactic categories
var_1 <- sapply(selected_vars.list[[3]], `[`, 1)
var_2 <- sapply(selected_vars.list[[3]], `[`, 2)
var_3 <- sapply(selected_vars.list[[3]], `[`, 3)
nomen.v <- paste(var_1, var_2, var_3, sep = "_And_")
r <- nrow(sample.df)
c <- length(nomen.v)
r <- nrow(online.df)
c <- length(nomen.v)
triplex_sample.df <- matrix(ncol = c, nrow = r)
colnames(triplex_sample.df) <- nomen.v
for (i in seq_along(var_1)) {
triplex_sample.df[, nomen.v[i]] <- paste( unlist(online.df[, var_1[i]]), unlist(online.df[, var_2[i] ]),
unlist(online.df[, var_3[i] ]),         sep = "_And_")
}
triplex_sample.df <- as.data.frame(triplex_sample.df)
freq.tib_three_plex <- gather(triplex_sample.df[,  ], variable_name, variable_value,  na.rm = TRUE) %>%
mutate(combined = paste(paste(variable_name, variable_value, sep = "_Are_"))) %>%
select( combined) %>%
group_by( combined) %>%
summarize(freq = n())  %>%
arrange(desc(freq))
freq.tib_simplex <- freq.tib_simplex %>%
filter(!str_detect(combined, "NA"))
freq.tib_two_plex <- freq.tib_two_plex %>%
filter(!str_detect(combined, "NA"))
freq.tib_three_plex <- freq.tib_three_plex %>%
filter(!str_detect(combined, "NA"))
View(freq.tib_three_plex)
View(freq.tib_two_plex)
setwd("~/Github/vedic/vedic_sandbox")
# drop all rows with frequency less than 5% of words
y <- nrow(online.df)*.05
freq.tib_simplex %>%
filter(freq >= y)
simplex_vars.tib <- freq.tib_simplex %>%
filter(freq >= y)
two_plex.vars.tib <- freq.tib_two_plex %>%
filter(freq >= y)
three_plex_vars.tib <-  freq.tib_three_plex %>%
filter(freq >= y)
saveRDS(simplex_vars.tib, "simplex_5pc.RDS")
setwd("~/Github/vedic/vedic_sandbox/vars")
saveRDS(simplex_vars.tib, "simplex_5pc.RDS")
saveRDS(two_plex.vars.tib, "two_plex_5pc.RDS")
saveRDS(three_plex_vars.tib, "three_plex_5pc.RDS")
# code to populate matrix with selected var value pairs
rm(list = ls())
library(magrittr)
simplex_vars.tib <- readRDS(file = "simplex_5pc.RDS")
two_tuple_vars.tib <- readRDS(file = "two_plex_5pc.RDS")
three_tuple_vars.tib <- readRDS(file = "three_plex_5pc.RDS")
simplex_comb.l <- simplex_vars.tib$combined %>% #split variable and value and store in list object
str_split("_Is_")
simplex_vars.tib
simplex_vars.tib$combined %>% #split variable and value and store in list object
str_split("_Is_")
two_tuple_vars.tib$combined %>%
str_split("_Are_")
two_comb.l <- two_tuple_vars.tib$combined %>%
str_split("_Are_")
# split the var name of each list element into component parts and store in new list
# each list element contains a vector with 2 elements
two_var.l <- sapply(two_comb.l, extract, 1) %>% # extract() needs package magrittr
str_split("_And_")
# split the value name of each list element into component parts and store in  new list
# each list element contains a vector with 2 elements
two_val.l <- sapply(two_comb.l, extract, 2) %>%
str_split("_And_")
# split variable and value and store in list object
# there is one vector per list element
# the first element of each vector contains var name, the second contains var value
three_comb.l <- three_tuple_vars.tib$combined %>%
str_split("_Are_")
# split the var name of each list element into component parts and store in new list
# each list element contains a vector with 3 elements
three_var.l <- sapply(three_comb.l, extract, 1) %>%
str_split("_And_")
# split the value name of each list element into component parts and store in  new list
# each list element contains a vector with 3 elements
three_val.l <- sapply(three_comb.l, extract, 2) %>%
str_split("_And_")
working.df <- readRDS("~/Github/vedic/vedic_sandbox/online_parse_eval.RDS")
View(working.df)
gold.df <- readRDS("~/Github/vedic/vedic_sandbox/gold_parse_eval.RDS")
rm(working.df)
online.df <- readRDS("~/Github/vedic/vedic_sandbox/online_parse_eval.RDS")
x <-  gold.df$sentence_id %>%
str_extract( "[^_]*")
online.df <- add_column(online.df, work_ref = x, .before = TRUE)
View(online.df)
saveRDS(online.df, file = "online_ref_by_work.RDS")
setwd("~/Github/vedic/vedic_sandbox")
saveRDS(online.df, file = "online_ref_by_work.RDS")
working.df <- readRDS("online_ref_by_work.RDS")
target.df <- working.df # create new df
target.df[, simplex_vars.tib$combined ] <- NA
target.df[, two_tuple_vars.tib$combined ] <- NA
target.df[, three_tuple_vars.tib$combined ] <- NA
for (j in seq_along(simplex_comb.l)) {
target.df[which(working.df[, simplex_comb.l[[j]][1]  ]  == simplex_comb.l[[j]][2]   ),
simplex_vars.tib$combined[j]   ] <- 1
# which() identifies rows in target in which var column of working.df (working.df[, simplex_comb.l[[j]][1]  ])
# has value required (simplex_comb.l[[j]][2] ); such cells are given value 1
target.df[which(is.na(target.df[, simplex_vars.tib$combined[j] ])), simplex_vars.tib$combined[j]  ] <- 0
# all other cells are given value 0
}
View(target.df)
for (j in seq_along(two_var.l)) {
target.df[which(working.df[, two_var.l[[j]][1] ] == two_val.l[[j]][1] &  working.df[, two_var.l[[j]][2] ]
== two_val.l[[j]][2]),           two_tuple_vars.tib$combined[j]] <- 1
# the same process as in j loop above except that it identifies where 2 columns in working.df
# have the two values inticated in two_val.l.
target.df[which(is.na(target.df[, two_tuple_vars.tib$combined[j] ])), two_tuple_vars.tib$combined[j]  ] <- 0
}
for (j in seq_along(three_var.l)) {
target.df[which(working.df[, three_var.l[[j]][1] ]  == three_val.l[[j]][1]
& working.df[, three_var.l[[j]][2] ]  == three_val.l[[j]][2]
& working.df[, three_var.l[[j]][3] ]  == three_val.l[[j]][3]
)      , three_tuple_vars.tib$combined[j]    ]  <- 1
# the same process as in j loop above except that it identifies where 3 columns in working.df
# have the 3 values inticated in three_val.l.
target.df[which(is.na(target.df[, three_tuple_vars.tib$combined[j] ])), three_tuple_vars.tib$combined[j]  ] <- 0
}
target.df[, 500]
target.df[, 400]
setwd("~/Github/vedic/vedic_sandbox/binary_valued")
saveRDS(target.df,file = "online_binary_valued.RDS")
rm(list = ls())
working.df <- readRDS("~/Github/vedic/vedic_sandbox/binary_valued/online_binary_valued.RDS")
colnames(working.df)
works.v <- working.df$work_ref %>% unique()
tokenCount.l <- vector(mode = "list", length(works.v))
for (i in seq_along(tokenCount.l)) {
a <- online.df %>%
filter(work_ref == books.v[i]) %>%
nrow()
tokenCount.l[[i]] <- a
}
unlist(tokenCount.l) %>% sum()
colnames(working.df)
tokenCount.l <- vector(mode = "list", length(works.v))
for (i in seq_along(tokenCount.l)) {
a <- working.df %>%
filter(work_ref == books.v[i]) %>%
nrow()
tokenCount.l[[i]] <- a
}
unlist(tokenCount.l) %>% sum()
a <- working.df %>%
filter(work_ref == books.v[i])
tokenCount.l <- vector(mode = "list", length(works.v))
for (i in seq_along(tokenCount.l)) {
a <- working.df %>%
filter(work_ref == works.v[i]) %>%
nrow()
tokenCount.l[[i]] <- a
}
unlist(tokenCount.l) %>% sum()
tokenCount.l
tokenCount.l / 200
unlist(tokenCount.l) / 200
unlist(tokenCount.l) / 200 %>%
ceiling()
unlist(tokenCount.l) / 200 %>%
ceiling(1)
unlist(tokenCount.l) / 200 %>%
ceiling()
unlist(tokenCount.l) / 200 %>%
round()
a <- unlist(tokenCount.l) / 200
floor(a)
ceiling(a)
a <- floor(a)
require(caret)
x <- working.df %>%
filter(work_ref == works.v[[i]])
createDataPartition(x, times = 1, p = 1)
createDataPartition(x$work_ref, times = 1, p = 1)
createDataPartition(x$work_ref, times = 2, p = 1)
createDataPartition(x$work_ref, times = 2, p = .5)
createDataPartition(x$work_ref, times = 2, p = .25)
createDataPartition(x$work_ref, times = 1, p = .25)
createFolds(x$work_ref, 2)
z <- createFolds(x$work_ref, 2)
i <- 1
colnames(x)
str_detect(colnames(x), _Is_)
index.v <- str_detect(colnames(x), "_Is_")
index.v <-  which(str_detect(colnames(x), "_Is_") == TRUE)
index.v <- c(which(str_detect(colnames(x), "_Is_") == TRUE),
which(str_detect(colnames(x), "_Are_") == TRUE) )
x <- x[, index.v]
View(x)
works.v[[i]]
x <- working.df %>%
filter(work_ref == works.v[[i]])
index.v <- c(which(str_detect(colnames(x), "_Is_") == TRUE),
which(str_detect(colnames(x), "_Are_") == TRUE) )
x <- x[, index.v]
folds.l <- createFolds(x$parent_Number_Is_Sing, a[i])
folds.l
fold.holder.l <- vector(mode = "list", length(folds.l))
n <- 1
b <- x[folds.l[[n]], ] %>%
colSums()
b
nrow(b)
b <- x[folds.l[[n]], ]
b <- colSums(b) / nrow(b)
b
for (n in seq_along(folds.l)) {
b <- x[folds.l[[n]], ]
b <- colSums(b) / nrow(b)
fold.holder.l[[n]] <- b
}
fold.holder.l
chunk.df <- do.call(bind_rows, fold.holder.l)
View(chunk.df)
paste0(works.v[i], "_", 1:nrow(chunk.df))
chunk.df <- add_column(chunk.df, chunk_id = paste0(works.v[i], "_", 1:nrow(chunk.df)) )
chunk.df <- do.call(bind_rows, fold.holder.l)
chunk.df <- add_column(chunk.df, chunk_id = paste0(works.v[i], "_", 1:nrow(chunk.df)), .before = TRUE )
View(chunk.df)
df.holder.l <- vector(mode = "list", length(works.v))
df.holder.l <- vector(mode = "list", length(works.v))
for (i in seq_along(works.v)) {
x <- working.df %>%
filter(work_ref == works.v[[i]])
index.v <- c(which(str_detect(colnames(x), "_Is_") == TRUE),
which(str_detect(colnames(x), "_Are_") == TRUE) )
x <- x[, index.v]
folds.l <- createFolds(x$parent_Number_Is_Sing, a[i])
fold.holder.l <- vector(mode = "list", length(folds.l))
for (n in seq_along(folds.l)) {
b <- x[folds.l[[n]], ]
b <- colSums(b) / nrow(b)
fold.holder.l[[n]] <- b
}
chunk.df <- do.call(bind_rows, fold.holder.l)
chunk.df <- add_column(chunk.df, chunk_id = paste0(works.v[i], "_", 1:nrow(chunk.df)), .before = TRUE )
df.holder.l[[i]] <- chunk.df
}
results.df <- do.call(bind_rows, df.holder.l)
View(results.df)
saveRDS(results.df, file = "sample1.RDS")
