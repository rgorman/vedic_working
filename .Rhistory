y[, 169]
197*2
choose(10, 4)
y <- combn(x, 4, simplify = T)
s <- colSums(y)
m <- min(abs(s - t))
which(abs(s - t) == m)
y[, 55]
z <- c(2, 3, 5, 8, 9, 10)
x[z]
sum(x[z])
sum(x[z])/2
c1 <- combn(x[z], 3)
c1
c1 <- combn(x[z], 3, simplify = T)
c1 <- combn(x[z], 3, simplify = F)
c1
sum(c1)
sapply(c1, sum)
s <- sapply(c1, sum)
abs(s - 197)
c1[3]
seq(1, 10)
seq(3002, length.out  = 22)
seq(3002, length.out  = 22, by = 2)
seq(8002, length.out  = 22, by = 2)
seq(8002, length.out  = 29, by = 2)
seq(201, length.out  = 29, by = 1)
seq(201, length.out  = 128, by = 1)
.8/.057
require(tidyverse)
a <- c("POS". "G", "N", "C", "Dep")
a <- c("POS", "G", "N", "C", "Dep")
b c("POS", "G", "N", "C", "Dep")
b <-  c("POS", "G", "N", "C", "Dep")
combn(a)
combn(a, 1)
m <- 1:5
combn(a, )
combn(a, m)
combn(a, 1)
combn(a, 2)
combn(a, 3)
combn(a, 4)
combn(a, 5)
2^5
b <-  c("P_POS", "P_G", "P_N", "P_C", "P_Dep")
a <- c("S_POS", "S_G", "S_N", "S_C", "S_Dep")
combn(a, 5)
combn(c(a, b), 5)
combn(c(a, b), 1)
combn(c(a, b), 2)
combn(c(a, b), 3)
2^10
log(66)
x <- .833
exp(-x) / (1 + (exp(-x)))
exp(x) / (1 + (exp(x)))
## cross-entropy loss
y <- 1
y_hat <- 1
y_hat^y * ((1-y_hat)^(1-y))
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
y_hat^y
((1-y_hat)^(1-y))
(1-y_hat)
(1-y)
((1-y_hat)^(1-y))
y_hat^y * ((1-y_hat)^(1-y))
## cross-entropy loss
y <- 0
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
log(y_hat^y * ((1-y_hat)^(1-y)))
## cross-entropy loss
y <- 1
y_hat <- .75
y_hat^y * ((1-y_hat)^(1-y))
log(y_hat^y * ((1-y_hat)^(1-y)))
-log(y_hat^y * ((1-y_hat)^(1-y)))
y_hat <- .7
y_hat^y * ((1-y_hat)^(1-y))
-log(y_hat^y * ((1-y_hat)^(1-y)))
(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
## cross-entropy loss
y <- 0
y_hat^y * ((1-y_hat)^(1-y))
-log(y_hat^y * ((1-y_hat)^(1-y)))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-(y*log(y_hat)) + ((1-y)*log(1-y_hat))
(-(y*log(y_hat)) + ((1-y)*log(1-y_hat)))
((y*log(y_hat)) + ((1-y)*log(1-y_hat)))
-1*(y*log(y_hat)) + ((1-y)*log(1-y_hat))
-log(y_hat^y * ((1-y_hat)^(1-y)))
(y*log(y_hat)) + ((1-y)*log(1-y_hat)) * -1
###
xx <- c(3, 2)
###
x <- c(3, 2)
exp(-x) / (1 + (exp(-x)))
w <- c(0, 0, 0)
x*w
###
x <- c(3, 2, 1)
w <- c(0, 0, 0)
x*w
exp(x*w) / (1 + (exp(x*w)))
ss <- exp(x*w) / (1 + (exp(x*w)))
ss - 1
(ss - 1) * x
g1 <- (ss - 1) * x
-.1 * g1
GNT.df <- readRDS("~/Github/GNT-stylometry/proiel/data/GNT_binary_valued.RDS")
colnames(GNT.df)[1:100]
require(tidyverse)
GNT.df$book_id %>% unique()
Hebr.df <- GNT.df %>%
filter(book_id = "HEB")
Hebr.df <- GNT.df %>%
filter(book_id == "HEB")
Rom.df <- GNT.df %>%
filter(book_id == "ROM")
GNT.df$self_proiel_pos %>% unique()
Hebr.df %>%
filter(self_proiel_pos == "common_noun")
View(Hebr.df)
Hebr.df %>%
filter(self_proiel_pos == "common_noun") %>%
select(id, form)
GNT.df$self_gender %>% unique()
GNT.df$self_gender
GNT.df$self_gender %>% unique()
Hebr.df %>%
filter(self_gender == "masculine_or_neuter")
Hebr.df %>%
filter(self_gender == "masculine_or_neuter") %>%
select(id, form)
View(Hebr.df)
Hebr.df %>%
filter(self_gender == "masculine_or_neuter") %>%
select(id, form, citation_part)
Hebr.df %>%
filter(self_case == "dative") %>%
select(id, form, citation_part)
Rom.df %>%
filter(self_case == "dative") %>%
select(id, form, citation_part)
Rom.df %>%
filter(self_case == "dative")
Rom.df %>%
filter(self_case == "dative") %>%
summarise(ct = n())
Rom.df %>%
filter(self_case == "dative") %>%
group_by(self_gender)
Rom.df %>%
filter(self_case == "dative") %>%
group_by(self_gender) %>%
summarise(ct = n())
x <- 20:40
20/x
30/33
names(x) <- x
20/x
25/40
25*(1/.625)
seq(1142, )
seq(1142, length.out = 141 )
seq(1283, length.out = 141 )
seq(1424, length.out = 141 )
seq(2001, length.out = 83 )
seq(2084, length.out = 83 )
seq(5223, length.out = 111 )
seq(5139, length.out = 138 )
seq(5277, length.out = 138 )
5277+138
140*20
seq(1103, length.out = 102 )
seq(1103, length.out = 100 )
seq(2085, length.out = 80 )
seq(2165, length.out = 80 )
seq(2245, length.out = 80 )
seq(3088, length.out = 90 )
seq(3178, length.out = 89 )
seq(5001, length.out = 135 )
seq(5136, length.out = 140 )
seq(5276, length.out = 140 )
seq(5416, length.out = 140 )
seq(5416, length.out = 135 )
seq(6001, length.out = 135 )
seq(6136, length.out = 140 )
seq(6276, length.out = 140 )
seq(6416, length.out = 140 )
seq(8084, length.out = 80 )
seq(1001, length.out = 101 )
seq(1102, length.out = 101 )
seq(1102, length.out = 110 )
seq(1212, length.out = 110 )
seq(1322, length.out = 110 )
seq(1322, length.out = 107 )
seq(2001, length.out = 82 )
seq(2082, length.out = 88 )
seq(2170, length.out = 88 )
seq(2258, length.out = 87 )
seq(2258, length.out = 22 )
seq(2001, length.out = 82 )
seq(3001, length.out = 90 )
seq(3091, length.out = 88 )
seq(3179, length.out = 88 )
seq(5144, length.out = 132 )
seq(5276, length.out = 132 )
seq(5408, length.out = 143 )
require(tidyverse)
x <- 1:5
combn(x, 2)
combn(x, 23)
combn(x, 5)
combn(x, 1)
combn(1:5, 1)
choose(5, 23)
online.df <- readRDS("~/Github/vedic/vedic_sandbox/formatted_online_parse.RDS")
require(tidyverse)
require(udpipe)
setwd("~/Github/vedic/UD_Sanskrit-Vedic")
test.df <- udpipe_read_conllu("sa_vedic-ud-test.conllu")
View(online.df)
View(test.df)
a <- test.df$token
b <- online.df$token
c <- a == b
which(c == FALSE)
View(online.df)
View(test.df)
str_detect(".", a)
require(writexl)
d <- bind_cols(a, b[1:9672])
View(d)
colnames(d)
colnames(d) <- c("gold", "test")
View(d)
write_xlsx(d, path = "2_cols.xlsx")
b[597]
b <- b[-597]
d <- bind_cols(a, b)
colnames(d) <- c("gold", "test")
write_xlsx(d, path = "2_cols.xlsx")
b %>% sub("\\.$", "", .)
e <- b %>% sub("\\.$", "", .)
a == e
f <- a == e
which(f == FALSE)
a[596]
e[596]
test.df$token <- f
online.df[595:600,]
online.df[597,]
swap.df <-  online.df[-597, ]
swap.df$token <- e
swap.df$lemma == test.df$token
swap.df$lemma == test.df$lemma
swap.df$lemma == test.df$lemma %>%
which(. == TRUE)
which(swap.df$lemma == test.df$lemma == TRUE)
which(swap.df$lemma == test.df$lemma) == TRUE)
which((swap.df$lemma == test.df$lemma) == TRUE)
which((swap.df$lemma == test.df$lemma) == TRUE) %>%
length()
which((swap.df$lemma == test.df$lemma) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$lemma == test.df$lemma) == TRUE)
index.v <- which((swap.df$lemma == test.df$lemma) == FALSE)
bind_cols(test.df$lemma[index.v], swap.df$lemma[index.v])
View(swap.df)
index.v <- which((swap.df$upos == test.df$upos) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$head_token_id == test.df$head_token_id) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$dep_rel == test.df$dep_rel) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Case == test.df$Case) == TRUE) %>%
length() / 9672
View(swap.df)
test.df$Case
View(test.df)
working.df <- test.df
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
m <- ncol(z) # for loop: number of cols in z
morphs.v <- NULL # vector to store results of loop
for (j in seq_len(m)) { # loop through cols of z
a <- z[, j] %>%
str_split(., "=") %>% # split name from value for each pair
sapply(., magrittr::extract, 1) # extract and keep only names, not values
morphs.v <- c(morphs.v, a) # put results in vector
b <- z[, j] %>%
str_split(., "=") %>% # split name from value for each pair
sapply(., magrittr::extract, 2) # extract and keep only vales, not names
}
morphs.v <-  unique(morphs.v) # remove duplicates
morphs.v <- morphs.v[- which(morphs.v == "")] # remove empty categories
morphs.v[which(is.na(morphs.v))] <- "Not_App" # rename NA: this is not an acceptable name for a col
working.df[, morphs.v] <- NA # add "self-" cols for morphology
z <- working.df$feats %>%
str_split(., "\\|", simplify = TRUE) # make a matrix of each name-value pair in the "feats" col of the input (e.g., "Case=Nom")
z[which(z == "")] <- "Not_App"
z[is.na(z)] <- "Not_App"
for (j in seq_len(ncol(z))) {
a <- apply(z[, j, drop=F], 1,   function(x) sub(".*=", "", x)    )
b <- apply(z[, j, drop=F], 1,   function(x) sub("=.*", "", x)    )
#b <- paste0("self_", b)
for (n in seq_along(a)) {
working.df[n, b[n]] <- a[n]
}
}
View(test.df)
View(working.df)
index.v <- which((swap.df$Case == working.df$Case) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Gender == working.df$Gender) == TRUE) %>%
length() / 9672
which((swap.df$Gender == working.df$Gender) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$VerbForm == working.df$VerbForm) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Tense == working.df$VerbForm) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Tense == working.df$Tense) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Number == working.df$Number) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Person == working.df$Person) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Voice == working.df$Person) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Voice == working.df$Voice) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Voice == test.df$Voicw) == FALSE)
index.v <- which((swap.df$Voice == test.df$Voice) == FALSE)
index.v <- which((swap.df$Voice == working.df$Voice) == FALSE)
working.df$Voice
swap.df$Voice
index.v <- which((swap.df$Voice == working.df$Voice) == TRUE) %>%
length() / 9672
index.v <- which((swap.df$Person == working.df$Person) == FALSE)
bind_cols(working.df$Person[index.v], swap.df$Person[index.v])
index.v <- which((swap.df$Person == working.df$Person) == TRUE)
bind_cols(working.df$Person[index.v], swap.df$Person[index.v])
index.v <- which((swap.df$Person == working.df$Person) == TRUE)
bind_cols(working.df$Person[index.v], swap.df$Person[index.v])
index.v <- which((swap.df$Case == working.df$Case) == TRUE)
which((swap.df$Case == working.df$Case) == FALSE)
index.v <- which((swap.df$Case == working.df$Case) == FALSE) %>%
length()
(9672 - index.v)
(9672 - index.v) / 9672
index.v <- which((swap.df$lemma == working.df$lemma) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$dep_rel == working.df$lemma) == FALSE) %>%
length()
index.v <- which((swap.df$dep_rel == working.df$dep_rel) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$Case == working.df$Case) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$Gender == working.df$Case) == FALSE) %>%
length()
index.v <- which((swap.df$Gender == working.df$Gender) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$VerbForm == working.df$VerbForm) == FALSE) %>%
length()
(9672 - index.v) / 9672
which((swap.df$VerbForm == working.df$VerbForm) == TRUE) %>%
length()
index.v <- which((swap.df$feats == working.df$feats) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$VerbForm == working.df$feats) == FALSE) %>%
length()
index.v <- which((swap.df$VerbForm == working.df$VerbForm) == FALSE) %>%
length()
(9672 - index.v) / 9672
which((swap.df$VerbForm == working.df$VerbForm) == TRUE) %>%
length()
333-4/333
(333-4)/333
x <- working.df$sentence_id %>%
unique() # vector with id number of each sentence
parent_holder.v <- NULL # vector to store result of loop
n <- 1
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
b
a$term_id[b]
add_column(global_token_id, 1:nrow(working.df), .before = TRUE)
add_column(global_token_id = 1:nrow(working.df), .before = TRUE)
add_column(working.df, global_token_id = 1:nrow(working.df), .before = TRUE)
parent_holder.v <- NULL # vector to store result of loop
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
View(a)
###
working.df <- add_column(working.df, global_token_id = 1:nrow(working.df), .before = TRUE)
x <- working.df$sentence_id %>%
unique() # vector with id number of each sentence
parent_holder.v <- NULL # vector to store result of loop
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
View(a)
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
c(parent_holder.v,  a$global_token_id[b]
c(parent_holder.v,  a$global_token_id[b] %>%
as.numeric() )
parent_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
#dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
#dd_holder.v <- c(dd_holder.v, (a$token_id %>%
as.numeric() ) - b )
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- working.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
parent_holder.v <- c(parent_holder.v,  a$global_token_id[b] %>%
as.numeric() ) # add parent term_token_id values for current sentence to vector
}
parent_holder.v
working.df <- add_column(working.df, global_parent_id = parent_holder.v, .before = TRUE)
View(working.df)
View(swap.df)
###
swap.df <- add_column(swap.df, global_token_id = 1:nrow(swap.df), .before = TRUE)
x <- swap.df$sentence_id %>%
unique() # vector with id number of each sentence
parent_holder.v <- NULL # vector to store result of loop
for (n in seq_along(x)) { # loop to create vector of parent term_ids
a <- swap.df %>%
filter(sentence_id == x[n]) # df with rows sentence by sentence
b <- as.numeric(a$head_token_id) # vector with head_token_id for each row in sentence
b[which(b == 0)] <- NA # eliminate any head_token_id with value 0
parent_holder.v <- c(parent_holder.v,  a$global_token_id[b] %>%
as.numeric() ) # add parent term_token_id values for current sentence to vector
}
parent_holder.v
swap.df <- add_column(swap.df, global_parent_id = parent_holder.v, .before = TRUE)
View(swap.df)
nomina.v <- colnames(working.df)
nomina.v
nomina.v[c(10, 14:25)]
nomina.v[c(10, 14, 17, 18, 20:25)]
nomina.v <-  nomina.v[c(10, 14, 17, 18, 20:25)]
x <- working.df$global_parent_id
nomina.v %>% paste0("parent_", .)
nominaq.v <-  nomina.v %>% paste0("parent_", .)
p_nomina.v <-  nomina.v %>% paste0("parent_", .)
working.df[, p_nomina.v] <-   working.df[x, nomina.v]
swap.df[, p_nomina.v] <-   swap.df[x, nomina.v]
View(swap.df)
index.v <- which((swap.df$parent_upos == working.df$parent_upos) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$dep_rel == working.df$parent_upos) == FALSE) %>%
length()
index.v <- which((swap.df$dep_rel == working.df$dep_rel) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$parent_dep_rel == working.df$parent_dep_rel) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$parent_Case == working.df$parent_Case) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$parent_Gender == working.df$parent_Gender) == FALSE) %>%
length()
(9672 - index.v) / 9672
index.v <- which((swap.df$parent_Tense == working.df$parent_Tense) == FALSE) %>%
length()
(9672 - index.v) / 9672
which(is.na(working.df$parent_Tense) == FALSE)
which(is.na(working.df$parent_Tense) == FALSE) %>%
length()
index.v <- which((swap.df$parent_Number == working.df$parent_Number) == FALSE) %>%
length()
(9672 - index.v) / 9672
which(is.na(working.df$parent_Number) == FALSE) %>%
length()
working.df$sentence_id
working.df$sentence_id %>% unique()
z <- working.df$sentence_id %>% unique()
z[1000]
z[1000:1473]
setwd("~/Github/vedic/vedic_sandbox")
saveRDS(swap.df, file = "online_parse_eval.RDS")
saveRDS(working.df, file = "gold_parse_eval.RDS")
